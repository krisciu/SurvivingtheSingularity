{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f20e6df",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install numpy torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4483b77c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d3c3f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used https://www.kaggle.com/code/aakashns/pytorch-basics-linear-regression-from-scratch \n",
    "# Used https://d2l.ai/chapter_linear-regression/linear-regression-scratch.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48cc42ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define our data\n",
    "\n",
    "#lets predict the cost of nutrient-cuboids in a region given the number of Neural-Enforcers,\n",
    "    #Price of \"life-force retainment fee(in trash cubes)\n",
    "    # and something else idk\n",
    "\n",
    "\n",
    "core_input_data = torch.round(torch.abs(torch.randn(50,3)) * 1000)\n",
    "\n",
    "print(core_input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f54e1dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "core_output_data = torch.round(torch.abs(torch.randn(50,1)) * 1000)\n",
    "print(core_output_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d464eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define our weights\n",
    "weights = torch.randn(3, 1, requires_grad=True)\n",
    "print(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2605f440",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define our bias\n",
    "bias = torch.randn(1,requires_grad=True)\n",
    "print(bias)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bdacd53",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets group these in an array\n",
    "\n",
    "parameters = [weights, bias]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c426485",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets define learning rate\n",
    "learning_rate = 1e-7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9061ad9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we define our loss function as squared loss\n",
    "def mean_squared_error(predicted_value, actual_value):\n",
    "        diff = predicted_value - actual_value\n",
    "        return torch.sum(diff * diff) / diff.numel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c45ef2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define our optimizer\n",
    "def sgd_optimize(parameters, learning_rate):\n",
    "    for parameter in parameters:\n",
    "        parameter -= learning_rate * parameter.grad\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ecbec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# and our optimizer reset\n",
    "def reset_gradients(parameters):\n",
    "    for parameter in parameters:\n",
    "        if parameter.grad is not None:\n",
    "            parameter.grad.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c3e4ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets define our actual model\n",
    "#remember, its just the matrix-vector product of the input matrix and our weights, plus our bias\n",
    "def model_predict(input_matrix, weights, bias):\n",
    "    return torch.matmul(input_matrix, weights) + bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8611776",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets see a single run of our model\n",
    "\n",
    "one_prediction = model_predict(core_input_data, weights, bias)\n",
    "\n",
    "print(one_prediction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed382f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "#now lets calculate our error\n",
    "loss = mean_squared_error(one_prediction, core_output_data)\n",
    "print(loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d01db003",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can check the gradients of our tensors wrt to loss\n",
    "loss.backward()\n",
    "print(weights)\n",
    "print(weights.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38f915ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#our gradients are positive, then the value and the loss are positively correlated(increasing value increases loss)\n",
    "# if not negatively correlated\n",
    "print(parameters[0].grad)\n",
    "print(weights.grad)\n",
    "print(parameters[1].grad)\n",
    "print(bias.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f4228a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#now we can optimize\n",
    "with torch.no_grad():\n",
    "    print(sgd_optimize(parameters, 1e-5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51785ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c62fca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we want to reset\n",
    "#reset_gradients(parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5798b011",
   "metadata": {},
   "outputs": [],
   "source": [
    "#now we can define a train\n",
    "\n",
    "def train(epoch, parameters, learning_rate, input_data, output_data):\n",
    "    for i in range(epoch):\n",
    "        prediction = model_predict(input_data, parameters[0], parameters[1])\n",
    "        loss = mean_squared_error(prediction, output_data)\n",
    "        loss.backward()\n",
    "        with torch.no_grad():\n",
    "            sgd_optimize(parameters, learning_rate)\n",
    "        reset_gradients(parameters)\n",
    "        print(i)\n",
    "        print(loss)\n",
    "        \n",
    "            \n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c62d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets train our model\n",
    "\n",
    "train(100, parameters, learning_rate, core_input_data, core_output_data )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e02cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's see how we did!\n",
    "prediction = model_predict(core_input_data, parameters[0], parameters[1])\n",
    "print(prediction)\n",
    "final_loss = mean_squared_error(prediction, core_output_data)\n",
    "print(final_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de5697e",
   "metadata": {},
   "outputs": [],
   "source": [
    "##TODO: later on, we willl add a loss function\n",
    "\n",
    "def L2(x):\n",
    "    return ((x ** 2).sum()) / 2\n",
    "\n",
    "def loss_function(predicted_value, actual_value, reg_constant, weights):\n",
    "    return (mean_squared_error(predicted_value, actual_value) +\n",
    "            (reg_constant * L2(weights)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cbc495e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we can add our new loss function\n",
    "\n",
    "def train_with_weight_decay(epoch, parameters, learning_rate, input_data, output_data, reg_constant):\n",
    "    for i in range(epoch):\n",
    "        prediction = model_predict(input_data, parameters[0], parameters[1])\n",
    "        loss = loss_function(prediction, output_data, reg_constant, parameters[0])\n",
    "        loss.backward()\n",
    "        with torch.no_grad():\n",
    "            sgd_optimize(parameters, learning_rate)\n",
    "        reset_gradients(parameters)\n",
    "        print(i)\n",
    "        print(loss)\n",
    "        \n",
    "            \n",
    "    return prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf37da42",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_with_weight_decay(100, parameters, learning_rate, core_input_data, core_output_data, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc1b826",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model_predict(core_input_data, parameters[0], parameters[1])\n",
    "print(prediction)\n",
    "final_loss = loss_function(prediction, core_output_data, 2, parameters[0] )\n",
    "print(final_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe0330b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
